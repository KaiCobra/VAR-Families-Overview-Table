# VAR Families Overview Table
This table summarizes third-party usage and research projects in the Visual Autoregressive Modeling (VAR) series, including project names, dates, GitHub links, conference information, and brief descriptions of features or tasks.
# VAR Families Overview Table

This table summarizes research projects related to Visual Autoregressive Modeling (VAR),
including core generative models and VAR-based applications.

| **Name** | **Date** | **Status / Conference** | **Link** | **Scope** | **Brief Description** |
|---------|---------|------------------------|---------|-----------|-----------------------|
| **MVAR** | 2025-05-19 | ICLR 2026 (under review) | [GitHub](https://github.com/LabShuHangGU/MVAR) | Core VAR Model | Scale & spatial Markovian conditioning for efficient VAR |
| **EAR** | 2025-05-12 | ICML 2025 | [GitHub](https://github.com/shaochenze/EAR) | Core VAR Model | Continuous VAR via score maximization |
| **FastVAR** | 2025-04-07 | arXiv | [GitHub](https://github.com/csguoh/FastVAR) | Core VAR Model | Cached token pruning for linear-time VAR |
| **FlexVAR** | 2025-02-27 | arXiv | [GitHub](https://github.com/jiaosiyu1999/FlexVAR) | Core VAR Model | VAR without residual prediction |
| **M-VAR** | 2024-11-15 | arXiv | [GitHub](https://github.com/OliverRensu/MVAR) | Core VAR Model | Decoupled scale-wise autoregressive modeling |
| **LiteVAR** | 2024-11-26 | arXiv | [arXiv](https://arxiv.org/abs/2411.17178) | Core VAR Model | Efficient attention & quantization for VAR compression |
| **HART** | 2024-10-14 | ICLR 2025 | [GitHub](https://github.com/mit-han-lab/hart) | Core VAR Model | Hybrid discrete-continuous autoregressive transformer |
| **Infinity** | 2024-12-05 | CVPR 2025 | [GitHub](https://github.com/FoundationVision/Infinity) | Core AR Model | Bitwise autoregressive modeling for high-res images |
| **Switti** | 2024-12-05 | CVPR 2025 | [GitHub](https://github.com/yandex-research/switti) | Core AR Model | Scale-wise transformer for text-to-image |

| **Name** | **Date** | **Status / Conference** | **Link** | **Scope** | **Brief Description** |
|---------|---------|------------------------|---------|-----------|-----------------------|
| **VARGPT** | 2025-01-21 | arXiv | [GitHub](https://github.com/VARGPT-family/VARGPT) | Multimodal VAR | Unified multimodal understanding & generation |
| **VARGPT-v1.1** | 2025-04-03 | arXiv | [GitHub](https://github.com/VARGPT-family/VARGPT-v1.1) | Multimodal VAR | Instruction tuning & RL for VAR-GPT |
| **GFT** | 2025-01-26 | ICML 2025 | [GitHub](https://github.com/thu-ml/GFT) | Training Strategy | Guidance-free visual generation |
| **CCA** | 2024-10-12 | ICLR 2025 (Oral) | [GitHub](https://github.com/thu-ml/CCA) | Training Strategy | Condition contrastive alignment for AR generation |
| **Distilled Decoding** | 2024-12-22 | ICLR 2025 | [GitHub](https://github.com/imagination-research/distilled-decoding) | Sampling | One-step AR sampling via flow matching |
| **FlowAR** | 2024-12-19 | arXiv | [GitHub](https://github.com/OliverRensu/FlowAR) | Sampling | Scale-wise AR meets flow matching |

| **Name** | **Date** | **Status / Conference** | **Link** | **Scope** | **Brief Description** |
|---------|---------|------------------------|---------|-----------|-----------------------|
| **AREdit** | 2025-03-31 | arXiv | [GitHub](https://github.com/wyf0912/AREdit) | Image Editing | Training-free text-guided editing |
| **ArchonView** | 2025-03-17 | arXiv | [GitHub](https://github.com/Shiran-Yuan/ArchonView) | View Synthesis | Zero-shot single-image novel view |
| **Safe-VAR** | 2025-03-14 | arXiv | [arXiv](https://arxiv.org/abs/2503.11324) | Watermarking | Safe text-to-image VAR |
| **VARSR** | 2025-01-31 | ICML 2025 | [GitHub](https://github.com/quyp2000/VARSR) | Super-Resolution | VAR for image SR |
| **Varformer** | 2024-12-30 | arXiv | [arXiv](https://arxiv.org/abs/2412.21063) | Restoration | VAR prior for restoration |
| **Medical Image Segmentation** | 2025-02-28 | arXiv | [arXiv](https://arxiv.org/abs/2502.20784) | Medical Imaging | Next-scale mask prediction |
| **FedGAT** | 2025-05-08 | arXiv | [GitHub](https://github.com/icon-lab/FedGAT) | Medical Imaging | Federated MRI reconstruction |
| **MARS** | 2025-02-17 | arXiv | [arXiv](https://arxiv.org/abs/2502.11390) | 3D Generation | Mesh autoregressive detailization |
| **SAR3D** | 2024-11-27 | CVPR 2025 | [GitHub](https://github.com/cyw-3d/SAR3D) | 3D Generation | Multi-scale 3D VQVAE |
| **VAT** | 2024-12-13 | arXiv | [GitHub](https://github.com/sparse-mvs-2/VAT) | 3D Generation | Variational tokenizer for AR 3D |
| **CARP** | 2024-12-09 | arXiv | [Website](https://carp-robot.github.io/) | Robotics | Coarse-to-fine visuomotor AR |
| **TokenFlow** | 2024-12-04 | CVPR 2025 | [GitHub](https://github.com/ByteFlow-AI/TokenFlow) | Tokenizer | Unified image tokenizer |
| **XQ-GAN** | 2024-12-03 | arXiv | [GitHub](https://github.com/lxa9867/ImageFolder) | Tokenizer | Open-source image tokenization |
| **CoDe** | 2024-11-28 | CVPR 2025 | [GitHub](https://github.com/czg1225/CoDe) | Decoding | Collaborative decoding for VAR |
| **Scalable AR Depth** | 2024-11-28 | CVPR 2025 | [arXiv](https://arxiv.org/abs/2411.11361) | Depth Estimation | Autoregressive monocular depth |
| **DDO** | 2025-03-03 | ICML 2025 | [NVIDIA](https://research.nvidia.com/labs/dir/ddo/) | Training Objective | Discriminative optimization for generative models |
| **Awesome-Multimodal-NTP** | 2024-12-30 | arXiv | [GitHub](https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction) | Survey | Multimodal NTP resources |


---

## Summary Statistics

**Total Projects:** 31

**Time Range:** October 12, 2024 - May 12, 2025

**Conference Breakdown:**
- **CVPR 2025:** 6 papers
- **ICML 2025:** 4 papers
- **ICLR 2025:** 2 papers (1 Oral)
- **Preprints/No Conference:** 19 papers

**Major Application Domains:**
- Image Generation & Editing (text-to-image, training-free editing)
- 3D Object Generation & Reconstruction
- Medical Image Processing & Segmentation
- Image Super-Resolution & Restoration
- Multimodal Understanding & Generation
- Depth Estimation
- Robotic Visuomotor Control

**Key Observations:**
- The VAR framework has inspired a rapidly growing ecosystem of research
- Strong presence at top-tier AI/CV conferences (CVPR, ICML, ICLR)
- Diverse applications spanning 2D/3D vision, medical imaging, and robotics
- Active development with multiple projects released in early 2025
